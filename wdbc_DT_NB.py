# -*- coding: utf-8 -*-
"""WDBC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ff_kf9euNg6tEHrQIE63uPXQj9gMDyvc
"""

#WDBC Dataset

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.tree import plot_tree
import sklearn.datasets
from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz
import pydotplus
from IPython.display import Image
import graphviz

!gdown 1ACLFDrJwD0r0fKHY-IX7COJWTYGr7Eyj

column_names = ["ID","Diagnosis",
    "mean radius", "mean texture", "mean perimeter", "mean area", "mean smoothness",
    "mean compactness", "mean concavity", "mean concave points", "mean symmetry", "mean fractal dimension",
    "radius error", "texture error", "perimeter error", "area error", "smoothness error",
    "compactness error", "concavity error", "concave points error", "symmetry error", "fractal dimension error",
    "worst radius", "worst texture", "worst perimeter", "worst area", "worst smoothness",
    "worst compactness", "worst concavity", "worst concave points", "worst symmetry", "worst fractal dimension"
]
df = pd.read_csv('wdbc.data',names = column_names)

X = df.drop(df.columns[[0,1]],axis=1)
Y = df[df.columns[1]]

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.30)

#Decision Tree Classifier

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion='entropy')
classifier.fit(X_train,Y_train)
y_pred  = classifier.predict(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print("Confusion Matrix:")
print(confusion_matrix(Y_test,y_pred))
print("------------------")
print("-------------------")
print('Classification Report:')
print(classification_report(Y_test,y_pred))

dot_data = export_graphviz(classifier, out_file=None, feature_names=X.columns, class_names=Y.unique(),
                           filled=True, rounded=True, special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data)
decision_tree_image_path = "decision_tree.png"
graph.write_png(decision_tree_image_path)
Image(decision_tree_image_path)

import seaborn as sns
cm = confusion_matrix(Y_test,y_pred)
sns.heatmap(cm,annot=True,fmt="d",cmap='magma')
plt.show

categories = ['90-10', '80-20', '70-30', '60-40', '50-50']
values = [0.96, 0.90,0.93, 0.92, 0.93]

plt.plot(categories, values)

plt.xlabel('Train-Test Division')
plt.ylabel('Accuracy')

plt.title('Comparison of Accuracy')

plt.show()

#MultinomialNB

from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB(alpha=3,fit_prior=True,class_prior=None).fit(X_train,Y_train)
classifier.fit(X_train,Y_train)
y_pred  = classifier.predict(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print("Confusion Matrix:")
print(confusion_matrix(Y_test,y_pred))
print("------------------")
print("-------------------")
print('Classification Report:')
print(classification_report(Y_test,y_pred))

import seaborn as sns
cm = confusion_matrix(Y_test,y_pred)
sns.heatmap(cm,annot=True,fmt="d",cmap='magma')
plt.show

categories = ['90-10', '80-20', '70-30', '60-40', '50-50']
values = [0.88, 0.87,0.92, 0.92, 0.91]
plt.plot(categories, values)
plt.xlabel('Train-Test Division')
plt.ylabel('Accuracy')
plt.title('Comparison of Accuracy')
plt.show()

#GaussianNB
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB(priors=None,var_smoothing=1e-05).fit(X_train,Y_train)
classifier.fit(X_train,Y_train)
y_pred  = classifier.predict(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print("Confusion Matrix:")
print(confusion_matrix(Y_test,y_pred))
print("------------------")
print("-------------------")
print('Classification Report:')
print(classification_report(Y_test,y_pred))

import seaborn as sns
cm = confusion_matrix(Y_test,y_pred)
sns.heatmap(cm,annot=True,fmt="d",cmap='magma')
plt.show

categories = ['90-10', '80-20', '70-30', '60-40', '50-50']
values = [0.91, 0.90, 0.92, 0.95, 0.93]
plt.plot(categories, values)
plt.xlabel('Train-Test Division')
plt.ylabel('Accuracy')
plt.title('Comparison of Accuracy')
plt.show()

#BernoulliNB
from sklearn.naive_bayes import BernoulliNB
classifier = BernoulliNB(alpha=3.0,binarize=2.9,fit_prior=True,class_prior=None).fit(X_train,Y_train)
classifier.fit(X_train,Y_train)
y_pred  = classifier.predict(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print("Confusion Matrix:")
print(confusion_matrix(Y_test,y_pred))
print("------------------")
print("-------------------")
print('Classification Report:')
print(classification_report(Y_test,y_pred))

import seaborn as sns
cm = confusion_matrix(Y_test,y_pred)
sns.heatmap(cm,annot=True,fmt="d",cmap='magma')
plt.show

categories = ['90-10', '80-20', '70-30', '60-40', '50-50']
values = [0.79, 0.78, 0.82, 0.81, 0.77]
plt.plot(categories, values)

plt.xlabel('Train-Test Division')
plt.ylabel('Accuracy')
plt.title('Comparison of Accuracy')
plt.show()