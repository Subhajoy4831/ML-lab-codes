# -*- coding: utf-8 -*-
"""Assn2_WDBC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n0mI177DXbN9G8smJo7PHG4ENylSs-fJ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc,zero_one_loss,accuracy_score
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,label_binarize
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.decomposition import PCA

!gdown 1ACLFDrJwD0r0fKHY-IX7COJWTYGr7Eyj
column_names = ["ID","Diagnosis",
    "mean radius", "mean texture", "mean perimeter", "mean area", "mean smoothness",
    "mean compactness", "mean concavity", "mean concave points", "mean symmetry", "mean fractal dimension",
    "radius error", "texture error", "perimeter error", "area error", "smoothness error",
    "compactness error", "concavity error", "concave points error", "symmetry error", "fractal dimension error",
    "worst radius", "worst texture", "worst perimeter", "worst area", "worst smoothness",
    "worst compactness", "worst concavity", "worst concave points", "worst symmetry", "worst fractal dimension"
]
df = pd.read_csv('wdbc.data',names = column_names)
X = df.drop(df.columns[[0,1]],axis=1)
Y = df[df.columns[1]]
Y = np.where(Y == 'M', 0, 1)
size=[0.30,0.40,0.50,0.60,0.70]

def classifier(clf,best_case,index):
  max = 0
  for i in range(0,len(size)):
    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=size[i])
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    clf.fit(X_train,Y_train)
    Y_pred = clf.predict(X_test)

    print("Confusion Matrix for test size",size[i],":")
    print(confusion_matrix(Y_test,Y_pred))
    print("Accuracy:")
    print(accuracy_score(Y_test,Y_pred)*100)
    if max<accuracy_score(Y_test,Y_pred):
      best_case[0] = X_train
      best_case[1] = X_test
      best_case[2] = Y_train
      best_case[3] = Y_test
      best_case[4] = Y_pred
      max=accuracy_score(Y_test,Y_pred)
      index = i
    print("--------------------------------------------------")
    print("--------------------------------------------------")

def perfReport(index,best_case):
  print("Confusion Matrix for test size",size[index],":")
  print(confusion_matrix(best_case[3],best_case[4]))
  print("Performance Report:")
  print(classification_report(best_case[3],best_case[4]))

def heatmap(best_case):
  cm = confusion_matrix(best_case[3],best_case[4])
  sns.heatmap(cm,annot=True,fmt="d",cmap='magma')
  plt.show()

def ROCcurve(best_case,clf):
  X_train,X_test, y_train, y_test = best_case[0],best_case[1],best_case[2],best_case[3]
  scores = None

  if clf==RFclf or clf==MLP_clf:
    scores = clf.predict_proba(X_test)
    prob_positive_class = scores[:, 1]
  else:
    decision_function = clf.decision_function(X_test)
    prob_positive_class = (decision_function - decision_function.min()) / (decision_function.max() - decision_function.min())

  fpr, tpr, _ = roc_curve(y_test, prob_positive_class)
  roc_auc = auc(fpr, tpr)

  plt.figure(figsize=(8, 6))
  plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
  plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title(f'ROC Curve for Binary Classification')
  plt.legend(loc='lower right')
  plt.show()

# Random Forest
RFclf = RandomForestClassifier(n_estimators=20)
rf_best_case = [0,0,0,0,0]
rf_index = 0
classifier(RFclf,rf_best_case,rf_index)

perfReport(rf_index,rf_best_case)

heatmap(rf_best_case)

ROCcurve(rf_best_case,RFclf)

#SVM_linear
linear_clf = SVC(kernel='linear',random_state=10)
linear_best_case = [0,0,0,0,0]
linear_index = 0
classifier(linear_clf,linear_best_case,linear_index)

perfReport(linear_index,linear_best_case)

heatmap(linear_best_case)

ROCcurve(linear_best_case,linear_clf)

#SVM_Polynomial
poly_clf = SVC(kernel='poly',random_state=10)
poly_best_case = [0,0,0,0,0]
poly_index = 0
classifier(poly_clf,poly_best_case,poly_index)

perfReport(poly_index,poly_best_case)

heatmap(poly_best_case)

ROCcurve(poly_best_case,poly_clf)

#SVM_Gussian
rbf_clf = SVC(kernel='rbf',random_state=10)
rbf_best_case = [0,0,0,0,0]
rbf_index = 0
classifier(rbf_clf,rbf_best_case,rbf_index)

perfReport(rbf_index,rbf_best_case)

heatmap(rbf_best_case)

ROCcurve(rbf_best_case,rbf_clf)

#SVM_sigmoid
sigmoid_clf = SVC(kernel='sigmoid',random_state=10)
sigmoid_best_case = [0,0,0,0,0]
sigmoid_index = 0
classifier(sigmoid_clf,sigmoid_best_case,sigmoid_index)

perfReport(sigmoid_index,sigmoid_best_case)

heatmap(sigmoid_best_case)

ROCcurve(sigmoid_best_case,sigmoid_clf)

# MLP
MLP_clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=900)
MLP_best_case = [0,0,0,0,0]
MLP_index = 0
classifier(MLP_clf,MLP_best_case,MLP_index)

perfReport(MLP_index,MLP_best_case)

heatmap(MLP_best_case)

ROCcurve(MLP_best_case,MLP_clf)

"""After Principal Component Analysis (PCA) for feature dimensionality reduction"""

def PCAformat(best_case):
  pca = PCA(n_components = 2)
  best_case[0] = pca.fit_transform(best_case[0])
  best_case[1] = pca.transform(best_case[1])

#RandomForest
PCAformat(rf_best_case)
RFclf = RandomForestClassifier(n_estimators=20)
RFclf.fit(rf_best_case[0],rf_best_case[2])
rf_best_case[4] = RFclf.predict(rf_best_case[1])
perfReport(rf_index,rf_best_case)

#SVM_linear
PCAformat(linear_best_case)
linear_clf = SVC(kernel='linear',random_state=10)
linear_clf.fit(linear_best_case[0],linear_best_case[2])
linear_best_case[4] = linear_clf.predict(linear_best_case[1])
perfReport(linear_index,linear_best_case)

#SVM_Polynomial
PCAformat(poly_best_case)
poly_clf = SVC(kernel='poly',random_state=10)
poly_clf.fit(poly_best_case[0],poly_best_case[2])
poly_best_case[4] = poly_clf.predict(poly_best_case[1])
perfReport(poly_index,poly_best_case)

#SVM_Gaussian
PCAformat(rbf_best_case)
rbf_clf = SVC(kernel='rbf',random_state=10)
rbf_clf.fit(rbf_best_case[0],rbf_best_case[2])
rbf_best_case[4] = rbf_clf.predict(rbf_best_case[1])
perfReport(rbf_index,rbf_best_case)

#SVM_Sigmoid
PCAformat(sigmoid_best_case)
sigmoid_clf = SVC(kernel='sigmoid',random_state=10)
sigmoid_clf.fit(sigmoid_best_case[0],sigmoid_best_case[2])
sigmoid_best_case[4] = sigmoid_clf.predict(sigmoid_best_case[1])
perfReport(sigmoid_index,sigmoid_best_case)

#MLP
PCAformat(MLP_best_case)
MLP_clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=900)
MLP_clf.fit(MLP_best_case[0],MLP_best_case[2])
MLP_best_case[4] = MLP_clf.predict(MLP_best_case[1])
perfReport(MLP_index,MLP_best_case)